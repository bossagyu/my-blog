[{"content":"Overview This article explains how to easily set up a TypeScript development environment using Volta, with MacOS as the target platform.\nWhat is Volta? Volta is a version management tool for Node.js, featuring the following characteristics as presented on Volta\u0026rsquo;s official site:\nFast: Built in Rust, enabling swift Node.js version switching. Reliable: Ensures everyone on a project uses the same tools. Universal: Can be used across package managers, node runtimes, and OSes. While nodebrew has been commonly used, the use of Volta seems to be increasing lately.\nInstalling Volta and Node.js Installing Volta is as simple as running the following command:\n1 curl https://get.volta.sh | bash If you\u0026rsquo;re using zsh and the path hasn\u0026rsquo;t been automatically set, use the following commands:\n1 2 3 echo \u0026#39;VOLTA_HOME=$HOME/.volta\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;export PATH=$VOLTA_HOME/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc Verify the installation. If a version is displayed, Volta has been successfully installed:\n1 volta -v Next, use Volta to install Node.js. If no version is specified, the latest LTS version will be installed:\n1 volta install node Installing yarn and Creating a TypeScript Project Differences between npm and yarn Both npm and yarn are package managers for Node.js. Their features include:\nnpm:\nReleased a year after Node.js (2010). Stands for Node Package Manager. Automatically generates a package-lock.json file. Installed automatically with Node.js. yarn:\nReleased in 2016. Developed by Facebook, Google, Exponent, and Tilde. Compatible with npm (can use the same package.json). More strict in locking module versions than npm. Faster installation than npm. While yarn appears superior, recent updates to npm have minimized the differences. Here, we will use yarn to create a TypeScript project.\nInstalling yarn Install yarn using Volta:\n1 volta install yarn Confirm the installation by checking if yarn is listed:\n1 volta list Creating a TypeScript Project Initialize yarn:\n1 yarn init -y Install Node.js:\n1 volta pin node@20.0.0 Install TypeScript:\n1 yarn add typescript Install ts-node:\n1 yarn add --dev ts-node Create a tsconfig.json file. This is a TypeScript configuration file that details compilation settings. In this case, you can leave it at the default settings generated:\n1 yarn tsc --init Test a sample program:\n1 2 3 4 echo \u0026#34;console.log(\u0026#39;Hello, TypeScript!\u0026#39;);\u0026#34; \u0026gt; hello.ts yarn ts-node hello.ts # If \u0026#34;Hello, TypeScript!\u0026#34; is displayed, it\u0026#39;s a success. The test script ran successfully. This completes the setup of the TypeScript development environment.\nSummary This article described how to set up a TypeScript development environment easily using Volta. By using Volta, managing Node.js versions becomes straightforward, making the development environment setup smoother. Additionally, specifying the Node.js version with Volta in your project\u0026rsquo;s package.json can help eliminate version discrepancies among developers, adding another layer of convenience to your workflow.\n","date":"2024-03-10T13:11:13+09:00","permalink":"https://bossagyu.com/en/blog/021-typescript-setup/","title":"Setting Up TypeScript Development Environment Easily with Volta"},{"content":"Overview This article explains capacity and performance management as outlined in ITIL v4. I will also apply what I have understood to my own experiences, explaining the process of capacity and performance management.\nWhat are Capacity and Performance Management? Capacity and Performance Management involves managing the performance of services and the resources supporting them. The goal is to optimize the performance of services and ensure that the capacity of services is appropriately maintained.\nProcesses in Capacity and Performance Management The processes in capacity and performance management include:\nEstablishing Capacity and Performance Control Analyzing and Improving Service Capacity and Performance Establishing Capacity and Performance Control Establishing capacity and performance control involves agreeing with stakeholders on the usage and performance standards for the IT resources used by the service, and deciding on the timing, baseline, and format for evaluation.\nIt is realized through the following steps:\nIdentifying service capacity and performance requirements Agreeing on service capacity and performance requirements Deciding on capacity and performance requirements Designing capacity and performance evaluation metrics and reports Applying my experiences to these processes, I understood them as follows:\nIdentifying service capacity and performance requirements As an internal platform provider, I identified latency performance requirements (99%ile in Nms) demanded by internal users. Based on these thresholds, we conducted performance verification and measured throughput per instance. We calculated the cost based on the throughput measurements. Agreeing on service capacity and performance requirements We agreed on latency performance and throughput with stakeholders. Deciding on capacity and performance requirements This remained unchanged from what was agreed upon. Designing capacity and performance evaluation metrics and reports We used a tracing tool called Dynatrace to measure and report performance. Analyzing and Improving Service Capacity and Performance Analyze issues in usage and performance conditions from service output logs and incident information.\nIt is realized through the following steps:\nAnalyzing capacity and performance Reporting capacity and performance Planning and designing capacity and performance Applying my experiences to these activities, I understood them as follows:\nAnalyzing capacity and performance We used Dynatrace to analyze latency performance and throughput. We identified performance issues from incident information. Reporting capacity and performance We visualized latency performance and throughput using Dynatrace\u0026rsquo;s dashboard. Planning and designing capacity and performance Anticipating growth in users, we forecasted that the current capacity would be insufficient. We made plans to increase capacity based on demand forecasts and executed them. Summary In this article, I explained capacity and performance management based on what I have learned and applied it to my own experiences. I understood that capacity and performance management involves managing aspects similar to availability management, but from the perspective of capacity and performance.\nIn my experience, discussions about performance and availability often go hand in hand, and I rarely deal with them independently.\n","date":"2024-02-27T08:53:36+09:00","permalink":"https://bossagyu.com/en/blog/020-itilv4-capacity-and-performance-management/","title":"Explaining Capacity and Performance Management in ITIL v4"},{"content":"Overview This article will guide you through installing Stable Diffusion Web UI on Mac and using it locally.\nWhat is Stable Diffusion? Stable Diffusion is a type of image processing technology using AI. By inputting text, it can generate images corresponding to that text.\nWays to Use Stable Diffusion There are two main ways to use Stable Diffusion:\nUsing web applications like Hugging Face or Dream Studio Using Stable Diffusion Web UI locally This article focuses on using Stable Diffusion Web UI locally. While web applications are easy for trial purposes, they might have limitations or costs for generating a significant number of images. Thus, local usage is recommended for more extensive needs.\nHow to Use Stable Diffusion Web UI Locally We will use stable-diffusion-web-ui published by AUTOMATIC1111 for this purpose.\nPrepare the environment Install stable-diffusion-web-ui Place the model files Start stable-diffusion-web-ui and generate images 1. Preparing the Environment First, we need to install Python and other necessary libraries using homebrew.\nInstall homebrew:\n1 /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; Set the homebrew path:\n1 export PATH=\u0026#34;$PATH:/opt/homebrew/bin/\u0026#34; Install related libraries:\n1 brew install cmake protobuf rust pyenv git wget Set up the Python environment using pyenv. This allows you to use multiple versions of Python. For building the Python environment, refer to this article.\n1 2 pyenv install 3.10.6 pyenv local 3.10.6 2. Installing stable-diffusion-web-ui Clone the repository using git clone:\n1 2 git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui Set up a virtual environment using venv to keep the environment clean:\n1 2 python -m venv venv source venv/bin/activate Now the environment is ready.\n3. Placing the Model Files Next, download the model files and place them in the stable-diffusion-webui/models/Stable-diffusion/ directory. Model files can be downloaded from sites like:\nCivitai Hugging Face For this example, we\u0026rsquo;ll download the blue_pencil model from Civitai.\nSearch for blue_pencil in Civitai\u0026rsquo;s search bar, select blue_pencil from the search results, and click the Download button.\nMove the downloaded model to the directory:\n1 mv ~/Downloads/bluePencilXL_v401.safetensors models/Stable-diffusion/ 4. Starting stable-diffusion-web-ui and Generating Images Finally, start stable-diffusion-web-ui and generate images:\n1 ./webui.sh After launching, input the text in the prompt and generate images:\nSelect the downloaded blue_pencil model in Stable Diffusion checkpoint. Enter elements you want in the image in the prompt. Enter elements you don\u0026rsquo;t want in the image in the Negative prompt. Click Generate. By inputting \u0026ldquo;a dog wearing pink sunglasses,\u0026rdquo; the output matched the input. You can generate various images by inputting different texts.\nSummary This article introduced how to install and use Stable Diffusion Web UI on Mac locally. Using it locally allows you to generate images freely without the limitations or costs associated with web applications.\n","date":"2024-02-12T11:24:59+09:00","permalink":"https://bossagyu.com/en/blog/019-stable-diffusion/","title":"How to Use Stable Diffusion Web UI on Mac"},{"content":"Overview This article consolidates my learning and understanding of business analysis as per ITIL v4. I will also apply my own experiences to explain the business analysis process.\nWhat is Business Analysis? Business analysis involves analyzing a business or any other component to propose solutions for meeting those needs or solving business challenges. It is important to note that the term \u0026ldquo;business\u0026rdquo; analysis does not solely pertain to business entities.\nExamples of Business Analysis Techniques Examples of business analysis techniques include:\nSWOT Analysis User Stories For specific methods, I defer to other sites as they are not the main focus here. Personally, I often use Customer Journey Maps, although it is not listed as an example here.\nThe Business Analysis Process The business analysis process includes two main processes:\nDesigning and Maintaining Business Analysis Approaches Identifying Business Analysis and Solutions Designing and Maintaining Business Analysis Approaches This process focuses on establishing a consistent and effective approach to business analysis by addressing the current and anticipated needs of the organization. It is executed as follows:\nAnalyzing the organization and requirements Reviewing business analysis approach methodologies Implementing the business analysis approach In my organization, we rarely conduct analysis at the business layer level. Generally, this process involves analyzing specific requirements using certain methodologies.\nIdentifying Business Analysis and Solutions This process emphasizes analyzing stakeholders\u0026rsquo; needs and requirements. It includes identifying and proposing solutions to address the stakeholders\u0026rsquo; needs and requirements. It is executed as follows:\nCollecting and analyzing information from stakeholders Defining solution options and identifying recommended solutions Providing support to the solution delivery team Evaluating and assessing the performance of the solution Applying my own experiences to these activities, I understood them as follows:\nFor 1,2 Collecting information from stakeholders and conducting analysis. Identifying the issues to be solved (why) from the analysis results and determining what solutions are available (what). For 3 Considering how to solve the identified why and what with the product team. Deciding on the resolution method and evaluation criteria to determine how success will be measured. For 4 Regularly evaluating how well the solution meets the established criteria. I recommend automating data collection and visualizing it with tools like Grafana for visibility. Summary This article explained business analysis based on my learning and experiences. Personally, I\u0026rsquo;ve understood that business analysis does not only target businesses and includes processes beyond analysis.\nReference Business analysis management: ITIL 4 Practice Guide ","date":"2024-02-09T09:00:56+09:00","permalink":"https://bossagyu.com/en/blog/018-itilv4-business-analysis/","title":"Explaining Business Analysis in ITIL v4"},{"content":"Overview This article explains how to set up and use GitHub Copilot in VSCode. A GitHub Copilot account is required as a prerequisite.\nGetting Started with GitHub Copilot in VSCode Installing the Extension First, you need to install the extension in VSCode. Open VSCode, click on the icon with four squares in the left menu, enter \u0026ldquo;copilot\u0026rdquo; in the search text input, and click \u0026ldquo;install\u0026rdquo; to start the installation.\nLinking with GitHub After clicking install and completing the installation, the following screen will appear. Click on \u0026ldquo;Sign in to GitHub.\u0026rdquo;\nYou will be asked to allow access to your GitHub account. Click \u0026ldquo;Allow\u0026rdquo; to grant permission.\nClick \u0026ldquo;Authorize Visual Studio Code\u0026rdquo; to give permission.\nThis completes the integration of GitHub Copilot with VSCode, and you\u0026rsquo;re now ready to use it.\nHow to Use Basically, as you write code, suggestions will automatically appear. Use the following commands to write code efficiently with the suggested completions.\nCheat Sheet Function Key Accept suggestion Tab Reject suggestion Esc Open Copilot Ctrl + Enter Next suggestion Alt/Option + ] Previous suggestion Alt/Option + [ Trigger inline Copilot Alt/Option + \\ Summary This article covered how to set up and use GitHub Copilot in VSCode.\nGitHub Copilot not only provides code completions but also assists with writing text.\nThis blog was also written with the assistance of GitHub Copilot, significantly improving efficiency.\nGive it a try and see how it can help you.\n","date":"2024-02-04T22:34:51+09:00","permalink":"https://bossagyu.com/en/blog/017-vscode-copilot/","title":"Setting Up and Using GitHub Copilot in VSCode"},{"content":"Overview This article explains availability management as defined in ITIL v4. I will also relate my own experiences to explain the processes involved in availability management.\nWhat is Availability Management? Availability management involves activities to ensure the availability of a service. The objective of availability management is to ensure that the service delivers an agreed level of availability to meet the needs of customers and users.\nProcesses in Availability Management There are two main processes in availability management:\nEstablishing Service Availability Control Analyzing and Improving Service Availability Establishing Service Availability Control Establishing service availability control ensures the availability of a service. It is realized through the following steps:\nIdentifying service availability requirements Agreeing on service availability requirements Deciding on availability measurement requirements Designing availability metrics and reporting Applying my own experiences to these processes, I understood them as follows:\nIdentifying service availability requirements Identifying the types of users and the business risks of service downtime. For my service, which is an internal platform, I identified the impacts on various services using the platform. Agreeing on service availability requirements Agreeing on the service\u0026rsquo;s availability (e.g., 99% uptime) in the form of an SLA. We also clarified downtime criteria and exceptions for uptime calculations. Deciding on availability measurement requirements As the availability requirements were agreed upon earlier, there were no specific measurement requirements. Designing availability metrics and reporting Primarily designed around the \u0026lsquo;downtime/uptime\u0026rsquo; formula. For reporting, we created a dashboard to visualize the availability metrics. Analyzing and Improving Service Availability This process, as the name suggests, involves analyzing and improving service availability. It is realized through the following steps:\nAnalyzing service availability Reporting on service availability Planning and designing for service availability Applying my own experiences to these processes, I understood them as follows:\nAnalyzing service availability Confirming that service availability is being achieved and compiling the data. Reporting on service availability Reflecting availability on a dashboard that is accessible to everyone. Planning and designing for service availability In case of incidents that affect availability, we formulated plans for prevention of recurrence. Reference Availability management: ITIL 4 Practice Guide ","date":"2024-01-30T20:34:58+09:00","permalink":"https://bossagyu.com/en/blog/016-itilv4-availability-management/","title":"Understanding Availability Management in ITIL v4"},{"content":"Overview This page explains how to check for the existence of an object in S3 using Python.\nMethod Using boto3 To check using boto3.resource, you can use the following code:\n1 2 3 4 5 6 7 8 9 10 s3 = boto3.resource(\u0026#39;s3\u0026#39;) try: s3.Object(\u0026#39;bucket_name\u0026#39;, \u0026#39;object_name\u0026#39;).load() print(\u0026#34;True\u0026#34;) except ClientError as e: error_code = e.response[\u0026#39;Error\u0026#39;][\u0026#39;Code\u0026#39;] if error_code == \u0026#39;404\u0026#39;: print(\u0026#34;Object does not exist.\u0026#34;) else: print(f\u0026#34;An error occurred: {e}\u0026#34;) If you\u0026rsquo;re using boto3.client, you can check with this code:\n1 2 3 4 5 6 7 8 9 10 s3 = boto3.client(\u0026#39;s3\u0026#39;) try: s3.head_object(Bucket=\u0026#39;bucket_name\u0026#39;, Key=\u0026#39;object_name\u0026#39;) print(\u0026#34;True\u0026#34;) except ClientError as e: error_code = e.response[\u0026#39;Error\u0026#39;][\u0026#39;Code\u0026#39;] if error_code == \u0026#39;404\u0026#39;: print(\u0026#34;Object does not exist.\u0026#34;) else: print(f\u0026#34;An error occurred: {e}\u0026#34;) Reference check if a file exists in s3 bucket using boto3 ","date":"2024-01-27T21:41:37+09:00","permalink":"https://bossagyu.com/en/blog/015-s3-object-check/","title":"Checking for the Existence of an Object in S3"},{"content":"Overview Integrating AWS API Gateway with Lambda enables you to call Lambda functions from API Gateway. This article introduces how to integrate AWS API Gateway with Lambda.\nPrerequisites It is assumed that the Lambda function has already been created. If not, please refer to the following article for creation:\nCreating an AWS Lambda function Deciding How to Integrate API Gateway with Lambda When integrating API Gateway with Lambda, you need to consider the following two points:\nThe request format for API Gateway Whether to use Proxy Integration or Non-Proxy Integration Request Format for API Gateway You can choose from the following formats:\nREST API HTTP API WebSocket API If you choose to use the REST API format, you will need to decide between REST API and HTTP API. While REST API has more features, it is more expensive than HTTP API. HTTP API is a good choice for simpler requirements.\nFor a detailed comparison, please refer to the official documentation.\nProxy vs. Non-Proxy Integration Using Proxy Integration standardizes the format of the response returned from Lambda. It is generally recommended to use Proxy Integration.\nSetting up Lambda Proxy Integrations in API Gateway Configuration After creating the Lambda function, select \u0026ldquo;Add Trigger.\u0026rdquo;\nChoose API Gateway.\nConfigure the trigger addition as shown below. Once configured successfully, the screen should look like this.\nAccess the API endpoint listed with a tool like curl to execute the Lambda function.\n1 2 3 $ curl https://xxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/default/apigateway-get-sample \u0026#34;Hello from Lambda!\u0026#34;% Summary This article introduced how to integrate AWS API Gateway with Lambda. By integrating with API Gateway, you can externally invoke Lambda functions at any time.\n","date":"2024-01-13T18:06:52+09:00","permalink":"https://bossagyu.com/en/blog/014-aws-apigateway-lambda/","title":"Integrating AWS API Gateway with Lambda"},{"content":"Overview This article summarizes how to create a good product strategy, based on the book \u0026ldquo;Good Strategy Bad Strategy.\u0026rdquo;\nBackground As a product owner in my job, I took over a product from the previous owner. The product lacked a clear strategy and direction, prompting me to develop a new product strategy.\nWhile developing the strategy, I realized that the term \u0026ldquo;strategy\u0026rdquo; is interpreted in various ways by different people, often used loosely in many contexts. To understand what constitutes a good strategy, I referred to \u0026ldquo;Good Strategy Bad Strategy.\u0026rdquo;\nWhat is a Good Strategy? A good strategy identifies critical points where concerted efforts can significantly boost the effect of oneâ€™s actions. A strategy should show the direction for an organization to move forward.\nA good strategy has three basic structures:\nDiagnosis Guiding Policy Actions Diagnosis Diagnosis involves assessing the situation to identify the key challenges to address. A good diagnosis separates crucial issues from the complex mix of problems and simplifies them.\nMost of the strategy work lies in figuring out what is happening. Gathering information is crucial. Although the book criticizes consultants\u0026rsquo; frameworks, I find them useful in organizing information after thorough collection.\nIn creating my product strategy, I used SWOT analysis and Impact Mapping to organize the current situation and the impact of existing strategies.\nFor more on these methods, refer to the following resources:\nSWOT Analysis Impact Mapping Guiding Policy The guiding policy outlines how to approach the challenges identified in the diagnosis. A good policy is not about goals or visions but about how to face challenges and exclude other options. It focuses efforts on a decisive point to achieve a significant effect.\nA good strategy clearly shows where resources will be allocated according to the strategy.\nIn my case, I defined the product direction based on the current situation and vision, focusing on specific target segments and values to offer.\nActions Actions are a coherent set of steps designed to execute the guiding policy. A strategy coordinates all actions to implement the policy effectively.\nA good strategy includes guidelines for implementing actions.\nMy Strategy Based on the above, I developed the following strategy (partially obscured as it was for my company):\n1 Reduce the new user cost of using xx function. This simple strategy meets the three basic structures of a good strategy:\nDiagnosis Identified increasing new users of xx as critical for the company\u0026rsquo;s benefit. Guiding Policy Decided to lower the onboarding cost to acquire new users. Actions Prioritized several approaches to realize the policy. Although it could have included more action-oriented words, I decided on the above. What is a Bad Strategy Finally, let\u0026rsquo;s touch on common patterns of bad strategies:\nCharacteristics of a Bad Strategy:\nVague Uses jargon or industry terms to obscure simple facts. Avoids Significant Problems Strategy should overcome difficult challenges and obstacles. Strategies focusing only on attainability are bad. Confuses Goals with Strategy For instance, a 10% revenue increase is a goal, not a strategy. Sets Wrong Strategic Objectives Strategies set without sufficient investigation of causes and surroundings. Summary This article summarized how to create a good product strategy based on \u0026ldquo;Good Strategy Bad Strategy.\u0026rdquo; Creating a good strategy might not happen at once. However, not having a strategy is like running blindly, unable to judge whether actions are successful or not.\nIt\u0026rsquo;s important to start with a basic strategy, constantly observe surroundings, and update the strategy to define the direction for your product and organization.\n","date":"2024-01-08T21:55:15+09:00","permalink":"https://bossagyu.com/en/blog/013-good-strategy-bad-strategy/","title":"How to Create a Product Strategy"},{"content":"Overview This article explains how to set up Twitter Social Cards for a blog created with Hugo.\nWhat is a Twitter Social Card? A Twitter Social Card is an image that is displayed when an article is shared on Twitter. The image below is an example of a Twitter Social Card.\nThere are several types of Twitter Social Cards, including:\nSummary Card Summary Card with Large Image App Card Player Card For sharing blog posts, the most commonly used types are Summary Card and Summary Card with Large Image.\nFor more details on each card type, refer to Twitter\u0026rsquo;s official documentation.\nHow to Set Up Twitter Social Cards There are two main methods to set up Twitter Social Cards:\nSetting up through the theme Setting up independently of the theme Setting Up Through the Theme Some themes allow you to set up Twitter Social Cards directly.\nFor this example, I\u0026rsquo;ll use the Stack theme that I\u0026rsquo;m using. In Stack, you can configure Twitter Social Cards in config.toml as follows:\n1 2 3 4 5 6 7 8 [opengraph.twitter] site = \u0026#34;\u0026#34; card = \u0026#34;summary\u0026#34; # summary or summary_large_image [defaultImage.opengraph] enabled = true local = false src = \u0026#34;/images/share.webp\u0026#34; # Path to the default image you want to set Setting Up Independently of the Theme If your theme doesnâ€™t support Twitter Social Card settings, you will need to implement it yourself.\nHugoâ€™s official template for implementation is available, which you can use for an easy setup.\nTroubleshooting If the settings donâ€™t seem to work, it might be due to incorrect implementation or the meta tags not being properly set. In such cases, use the debugging tool provided by Twitter to check if the settings have been correctly applied.\nSummary This article explained how to set up Twitter Social Cards for a blog created with Hugo. Setting up Social Cards can enhance the visibility of your shared articles on Twitter, potentially attracting more readers, so it\u0026rsquo;s definitely worth doing.\n","date":"2024-01-06T21:45:12+09:00","permalink":"https://bossagyu.com/en/blog/012-social-card/","title":"Setting Up Twitter Social Cards"},{"content":"Overview This article explains how to use ChatGPT to make a blog created with Hugo multilingual.\nTranslating Articles into English with ChatGPT You can translate articles written in Markdown into English using ChatGPT. When doing so, use the following prompt to ensure that the format remains intact:\n1 2 3 Please translate this Markdown into English without altering its format. Ensure that no extraneous output is included. Present the translated content in a format that can be easily copied. Paste your article in Japanese, and ChatGPT will output the translated Markdown. You can copy the output directly by clicking the copy button at the bottom left of the output.\nIt is highly recommended to use GPT-4 instead of GPT-3.5, despite the subscription cost. GPT-4 significantly outperforms GPT-3.5 in providing accurate responses, making it useful for purposes beyond just translation.\nMaking Hugo Multilingual Here are the steps to make your Hugo site multilingual.\nCreating Configuration Files Add the following settings to your config.toml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Set the default language, without this setting English is assumed default. defaultContentLanguage = \u0026#34;jp\u0026#34; [languages] # Set configurations for each language [languages.jp] title = \u0026#34;Bossagyu Blog\u0026#34; languageName = \u0026#34;ja-jp ðŸ‡¯ðŸ‡µ\u0026#34; LanguageCode = \u0026#34;ja-jp\u0026#34; contentDir = \u0026#34;content\u0026#34; # Directory for Japanese blog articles [languages.jp.params] [languages.en] title = \u0026#34;Bossagyu Blog\u0026#34; languageName = \u0026#34;en-US ðŸ‡ºðŸ‡¸\u0026#34; LanguageCode = \u0026#34;en-US\u0026#34; contentDir = \u0026#34;content.en\u0026#34; # Directory for English blog articles [languages.en.params] With the above settings, you can write Japanese articles in the content directory and English articles in the content.en directory to support multiple languages.\nThe final directory structure will look like this:\n1 2 3 4 5 6 7 8 9 10 11 project/ â”œâ”€â”€ content/ â”‚ â”œâ”€â”€ index.md â”‚ â””â”€â”€ blog/ â”‚ â”œâ”€â”€ index.md â”‚ â””â”€â”€ article1.md â””â”€â”€ content.en/ â”œâ”€â”€ index.md â””â”€â”€ blog/ â”œâ”€â”€ index.md â””â”€â”€ article1.en.md In the English directory, naming files as article-name.en.md identifies them as English versions of the default language articles, and language switch icons will be added to the articles. For the articles, just copy and paste the translations from ChatGPT.\nSummary This article explained how to make a Hugo blog multilingual using ChatGPT. Utilizing ChatGPT simplifies the translation process. Multilingual support can help reach audiences outside Japan, increasing readership.\nSince it\u0026rsquo;s low-cost and efficient, it\u0026rsquo;s worth giving it a try.\n","date":"2023-12-31T20:46:36+09:00","permalink":"https://bossagyu.com/en/blog/011-hugo-multilingul-support/","title":"Using ChatGPT to Make a Hugo Blog Multilingual"},{"content":"Overview This article explains a simple method to create a favicon. It also covers how to display a favicon in Hugo.\nWhat is a Favicon? A favicon is an icon that appears in bookmarks, tabs, and home screens for websites. Google has published guidelines for favicons that appear in search results. Adhering to these guidelines can help your favicon appear in search results.\nCreating a Favicon To create a favicon, use the following site:\nFavicon.ico \u0026amp; App Icon Generator When you visit the site, you\u0026rsquo;ll see a screen like this.\nEnter the URL of the site you want a favicon for and click on Generate Favicon. Then, on the displayed screen, click the \u0026lsquo;Download the generated favicon\u0026rsquo; link to download the favicon.\nDisplaying a Favicon in Hugo To display a favicon in Hugo, the process varies depending on the theme. For the bearcub theme, you can simply set it in the toml like this:\n1 2 [params] favicon = \u0026#34;images/favicon.ico\u0026#34; Summary This article explained how to create a favicon and display it in Hugo. Favicons are displayed in bookmarks, tabs, and home screens, so it\u0026rsquo;s a good idea to create one for your blog.\n","date":"2023-12-24T22:14:39+09:00","permalink":"https://bossagyu.com/en/blog/010-favicon/","title":"Creating and Displaying a Favicon with Hugo"},{"content":"Overview This article explains how to measure your blog\u0026rsquo;s performance using Lighthouse.\nWhat is Lighthouse? Lighthouse is a performance measurement tool for websites provided by Google. It\u0026rsquo;s available as a Google Chrome extension and can be used by installing the plugin.\nInstalling Lighthouse Install Lighthouse from the Chrome Web Store.\nOpen the site you want to analyze and click on the Lighthouse icon.\nClick on Generate report to start the analysis.\nThis time, I ran it on my blog page.\nThe results are displayed as follows, taking about 1 minute to complete.\nInterpreting the Results Performance Evaluates web performance, like page loading and image display speeds. Clicking the See calculator link takes you to more details.\nAccessibility Checks whether all users can access content and navigate efficiently within the site. Scrolling down shows areas flagged by Accessibility.\nIt points out weak color contrast in the code snippets and missing descriptions in links.\nHowever, the flagged content is not from my writing but depends on the template, so to fix this, it would be necessary to override the Hugo template.\nBest Practices Tests the integrity of web pages. You can view the testing items in the results.\nSEO You can check if the page is optimized for search engine result rankings.\nProgressive Web App Checks if the loading speed of web pages on smartphones is optimized and if it\u0026rsquo;s suitable for PWAs. This wasn\u0026rsquo;t checked in this case.\nSummary The article explained how to measure the performance of a blog using Lighthouse. Especially for SEO, as it affects visibility in Google search results, it\u0026rsquo;s important to address these issues adequately.\n","date":"2023-12-22T23:08:00+09:00","permalink":"https://bossagyu.com/en/blog/009-light-house/","title":"Introduction to Using Lighthouse"},{"content":"Overview This article explains how to schedule regular executions of Lambda functions using AWS EventBridge.\nPrerequisite It is assumed that the Lambda function has already been created.\nSteps Select the Lambda function and choose \u0026lsquo;Add trigger\u0026rsquo;.\nSelect \u0026lsquo;EventBridge\u0026rsquo; from the triggers.\nThe rule creation screen will appear. Configure the settings.\nFor this example, I set it to execute every 5 minutes using a cron expression.\nFor cron syntax, refer to the Schedule type on EventBridge Scheduler page.\nOnce configured, EventBridge will be added to the triggers in the Lambda function diagram.\nAs an aside, I created and tested a Function to send messages to LINE.\nNow, it sends notifications every 5 minutes like this.\nSummary This article explained how to schedule Lambda functions regularly using AWS EventBridge.\nKeep in mind that leaving the configured EventBridge running can incur charges, so delete it if it\u0026rsquo;s no longer needed.\n","date":"2023-12-21T23:03:13+09:00","permalink":"https://bossagyu.com/en/blog/008-aws-eventbrdge/","title":"Scheduling Lambda Functions Regularly Using AWS EventBridge"},{"content":"Overview To appear in Google searches, it\u0026rsquo;s not enough just to apply SEO strategies; your site must first be recognized by Google. This article explains how to make your own custom domain blog appear in Google search results using Google Search Console.\nSteps to Implementation Registering with Google Search Console Verifying Domain Ownership Registering the Sitemap Requesting Index Registration Summary Registering with Google Search Console Register on Google Search Console.\nChoose your domain and enter the URL.\nVerifying Domain Ownership A screen like the following will appear to verify DNS ownership.\n(The TXT record content is blacked out for privacy.)\nYou can verify ownership by adding a string specified by Google to your domain\u0026rsquo;s TXT record. Go to your domain\u0026rsquo;s DNS settings and add a TXT record.\nIn my case, I acquired the domain through Netlify, so I went to Netlify\u0026rsquo;s DNS settings. Navigate to Domains -\u0026gt; Domain Settings -\u0026gt; DNS Records and add the TXT record.\nCopy the content displayed on Google Search Console and paste it into the Value field.\n(The Value part is blacked out for privacy.)\nWait for DNS updates, which can take a few hours depending on the provider.\nYou can check DNS propagation from the command line.\n1 dig -t txt bossagyu.com Afterward, press the verify ownership button on Google Search Console.\nThis completes the verification process, and your domain will be registered with Google Search Console.\nRegistering the Sitemap Registering a sitemap informs Google about the structure of your site, facilitating the crawling process. For blogs created with Hugo, the sitemap is available at /sitemap.xml, which you should register.\nFrom the left menu of Google Search Console, select \u0026lsquo;Sitemaps\u0026rsquo; and add your sitemap.\nRequesting Index Registration Even if your site is registered in the sitemap, it can take time for Google to crawl and index it. In my case, I requested index registration after waiting several days without being indexed.\nSearch for the URL you want to register in Google Search Console, and click on \u0026lsquo;Request Indexing\u0026rsquo; found on the right side of the search result.\nThis requests index registration. It took a few hours for the index to be registered after clicking.\nSummary This article explained how to make your custom domain blog searchable using Google Search Console.\nIt\u0026rsquo;s a waste not to have your blog appear in Google searches after all the effort of creating it, so give it a try.\n","date":"2023-12-18T19:10:04+09:00","permalink":"https://bossagyu.com/en/blog/007-google-search-console/","title":"Using Google Search Console to Make Your Blog Searchable on Google"},{"content":"Overview This article explains how to efficiently develop Lambda functions using the AWS Toolkit in IntelliJ.\nSteps to Implementation Preliminary Preparation Installing AWS Toolkit Configuring AWS Toolkit Developing Lambda Executing Lambda Locally Summary Preliminary Preparation Installing Docker AWS Toolkit in IntelliJ uses Docker to run Lambda.\nPrior to proceeding, please install Docker by referring to these instructions.\nInstalling AWS CLI Install AWS CLI (SAM).\nFor installation, refer to these instructions.\nIn IntelliJ, set the path for SAM CLI executable under File -\u0026gt; Settings -\u0026gt; Tools -\u0026gt; AWS Toolkit.\nIn my case, as I installed it through brew, I set the following path.\nInstalling AWS Toolkit Install the AWS Toolkit via IntelliJ plugins. Refer to this guide for plugin installation.\nConfiguring AWS Toolkit To use AWS Toolkit, you need to set up your AWS credentials.\nSet up AWS credentials through AWS Explorer.\nObtain and configure your Access Key ID and Secret Access Key from the AWS console. Once configured, AWS resources should appear in AWS Explorer.\nNote: In this image, the region is set to us-east-1. Please adjust according to the region where you intend to create your Lambda.\nDeveloping Lambda Create a code snippet like the following.\nlambda-sample.py\n1 2 3 def lambda_handler(event, context): print(\u0026#34;Hello World\u0026#34;) return \u0026#34;Hello World!\u0026#34; Create a Lambda through AWS Explorer.\nSelect Create Lambda Function and input the necessary values.\nFor the Handler, enter \u0026lt;filename\u0026gt;.\u0026lt;function name\u0026gt; from your code snippet.\nThis completes the creation of your Lambda.\nExecuting Lambda Locally The Toolkit also allows you to execute Lambda locally. Selecting Run will execute the Lambda locally.\nSummary This article provided a guide on efficiently developing Lambda using AWS Toolkit in IntelliJ. Developing in IntelliJ and executing locally can significantly improve development efficiency.\n","date":"2023-12-12T22:40:05+09:00","permalink":"https://bossagyu.com/en/blog/006-intellij-lamda-setup/","title":"Efficient Lambda Development with AWS Toolkit in IntelliJ"},{"content":"Overview This article explains how to use GitHub Copilot in IntelliJ. Additionally, a cheat sheet of shortcuts is provided.\nSteps to Implementation Register for GitHub Copilot Configure IntelliJ Use GitHub Copilot Summary Registering for GitHub Copilot Register for GitHub Copilot through the GitHub Copilot link.\nConfiguring IntelliJ Install the GitHub Copilot plugin from IntelliJ plugins.\nOnce installed, restart IntelliJ.\nUsing GitHub Copilot When you write code in IntelliJ, GitHub Copilot will assist with code completion.\nHere is a list of shortcuts for Mac:\nShortcut Function tab Complete the code Option + ] Show the next completion suggestion Option + [ Show the previous completion suggestion Command + â†’ Accept only the next word of the suggestion Summary This article explained how to use GitHub Copilot in IntelliJ. It\u0026rsquo;s worth noting that this article was written using GitHub Copilot, and it significantly assists with blog creation in Markdown, so those interested should give it a try.\n","date":"2023-12-11T22:45:40+09:00","permalink":"https://bossagyu.com/en/blog/005-github-copilot/","title":"How to Use GitHub Copilot in IntelliJ"},{"content":"Overview This article documents how to set up a Python environment for development on a Mac local environment.\nIn this case, we will use two systems to manage different versions of Python and virtual environments:\npyenv Used to handle multiple versions of Python. venv Used to separate environments for each project. For explanations on the differences and the necessity of each, this article is a helpful reference.\nInstalling Python First, install Pyenv on your local environment to use a specific version of Python.\nInstall pyenv.\n1 brew install pyenv Check the installed version of pyenv.\n1 2 pyenv --version pyenv 2.3.35 Add settings to zsh.\n1 2 3 echo \u0026#39;export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo -e \u0026#39;if command -v pyenv 1\u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then\\n eval \u0026#34;$(pyenv init -)\u0026#34;\\nfi\u0026#39; \u0026gt;\u0026gt; ~/.zshrc Reload .zshrc.\n1 source ~/.zshrc Display a list of installable Python versions.\n1 pyenv install --list Install the specified version.\n1 pyenv install 3.11.7 Use the specified Python version in your project folder.\n1 2 3 cd \u0026lt;created project folder\u0026gt; pyenv local 3.11.7 pyenv versions If global, it will be applied to the entire system.\n1 pyenv global 3.11.7 Check the version of Python being executed.\n1 python -V Creating a Virtual Environment with venv Create a virtual environment in the project directory.\n1 2 # python -m venv \u0026lt;virtual environment name\u0026gt; python -m venv venv Activate the virtual environment.\n1 source venv/bin/activate To deactivate, execute the following command.\n1 deactivate This completes the setup of the local environment.\n","date":"2023-12-10T23:19:33+09:00","permalink":"https://bossagyu.com/en/blog/004-paython-setup/","title":"Setting Up a Local Environment Using Pyenv and venv"},{"content":"Overview This article briefly explains how to set up Google Analytics with Hugo.\nSteps to Implementation Register with Google Analytics Obtain the Tracking ID Add the Tracking ID to Hugo\u0026rsquo;s configuration Registering with Google Analytics Follow the instructions on Setting up a new website or app with GA4 to register.\nWhen you add a data stream, you will get a Tracking ID, so make a note of it. â€» The Tracking ID may be displayed as \u0026ldquo;Measurement ID\u0026rdquo; due to translation.\nAdding Tracking ID to Hugo\u0026rsquo;s Configuration Add settings in toml Add googleAnalytics = Tracking ID to your config.toml.\n1 2 3 4 5 6 baseURL = \u0026#39;https://bossagyu.com\u0026#39; languageCode = \u0026#39;ja-jp\u0026#39; title = \u0026#39;Bossagyu Blog\u0026#39; theme = \u0026#39;hugo-bearcub\u0026#39; googleAnalytics = \u0026#34;G-1234ABCDEF\u0026#34; # â†‘ Add this line, replace the Tracking ID with your own. Embedding the Tracking Code Some templates might read settings from the toml file, but the bearcub template I use does not support this, so I added the tracking code to the header myself.\nFor the code snippet, I referred to Makumaku Hugo Notes.\nCreate layouts/partials/analytics.html to load the tracking code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 {{ if not .Site.IsServer }} {{ with .Site.GoogleAnalytics }} \u0026lt;!-- Google tag (gtag.js) --\u0026gt; \u0026lt;script async src=\u0026#34;https://www.googletagmanager.com/gtag/js?id={{ . }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\u0026#39;js\u0026#39;, new Date()); gtag(\u0026#39;config\u0026#39;, \u0026#39;{{ . }}\u0026#39;); \u0026lt;/script\u0026gt; {{ end }} {{ end }} Make the page header load analytics.html.\n1 2 3 # Copy the content of the template to override it cp themes/hugo-bearcub/layouts/_default/baseof.html layouts/_default/baseof.html vim layouts/_default/baseof.html Add {{- partial \u0026quot;analytics\u0026quot; . -}} to baseof.html.\n1 2 3 4 5 6 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;{{ with .Site.LanguageCode }}{{ . }}{{ else }}en-US{{ end }}\u0026#34;\u0026gt; \u0026lt;head\u0026gt; {{- partial \u0026#34;analytics\u0026#34; . -}} \u0026lt;meta http-equiv=\u0026#34;X-Clacks-Overhead\u0026#34; content=\u0026#34;GNU Terry Pratchett\u0026#34; / After adding the above source code and rebuilding, data will be sent to Google Analytics.\nTips If it seems like data is not being transmitted to Google Analytics despite these steps, it\u0026rsquo;s possible that the tags have not been added correctly.\nTo troubleshoot, first check if the tracking is included in the HTML by using Google Developer Tools.\n","date":"2023-12-09T18:09:42+09:00","permalink":"https://bossagyu.com/en/blog/003-google-analytics/","title":"How to Set Up Google Analytics with Hugo"},{"content":"Overview I thought of creating an application using LINE\u0026rsquo;s Bot, so first, I will make the Bot usable.\nThis page introduces how to register for the LINE Messaging API and how to send messages from the command line using curl.\nUsing the Messaging API Log in to LINE Developers and create a provider.\nA provider is (Explanation)\n1 On the LINE Developers site, a service provider refers to individuals, companies, or organizations that provide services and obtain user information (service proprietor in LINE Mini Apps). So, you can enter any string you like.\nThen, create a new channel. Clicking the create button will establish a new channel.\nPosting from the Command Line Add friends by reading the QR code in the Messaging API settings.\nObtain the \u0026lsquo;Channel Access Token (Long-lived)\u0026rsquo; from the Messaging API settings. Get \u0026lsquo;Your User ID\u0026rsquo; from the channel basic settings.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 TOKEN=\u0026#34;\u0026lt;Channel Access Token (Long-lived)\u0026gt;\u0026#34; ID=\u0026#34;\u0026lt;Your User ID\u0026gt;\u0026#34; UUID=$(uuidgen | tr \u0026#34;[:upper:]\u0026#34; \u0026#34;[:lower:]\u0026#34;) curl -v -X POST https://api.line.me/v2/bot/message/push \\ -H \u0026#39;Content-Type: application/json\u0026#39; \\ -H \u0026#34;Authorization: Bearer ${TOKEN}\u0026#34; \\ -H \u0026#34;X-Line-Retry-Key: \u0026#34; \\ -d \u0026#34;{ \\\u0026#34;to\\\u0026#34;: \\\u0026#34;${ID}\\\u0026#34;, \\\u0026#34;messages\\\u0026#34;:[ { \\\u0026#34;type\\\u0026#34;:\\\u0026#34;text\\\u0026#34;, \\\u0026#34;text\\\u0026#34;:\\\u0026#34;Hello, world1\\\u0026#34; } ] }\u0026#34; If a response is returned and you see a post from the Bot in your LINE chat, it\u0026rsquo;s a success!\n","date":"2023-12-07T09:37:00+09:00","permalink":"https://bossagyu.com/en/blog/002-line-messaging-api/","title":"Registering and Using the LINE Messaging API"},{"content":"Overview This document describes the steps to create a site with Hugo, manage it with Github, and build it with Netlify from scratch.\nWith this method, you can easily publish by just pushing your Markdown-written blog to Github.\nProcess Generate a site with Hugo Push to Github Deploy with Netlify Generating a Static Site with Hugo First, install Hugo.\n1 brew install hugo Create a template for the blog.\n1 hugo new site my-blog Add a theme suitable for the blog as a submodule.\n1 2 3 4 5 cd my-blog git init # Add the theme as a submodule from Github git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke Apply the theme by adding it to hugo.toml.\n1 echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; config.toml Start the server.\n1 hugo server Access the URL like http://localhost:51517/ shown in the startup log Web Server is available at http://localhost:51517/ (bind address 127.0.0.1) to view the locally launched static site.\nTips If you want to change the Hugo theme, please choose your favorite one from Hugo Themes. It\u0026rsquo;s recommended to run through until you build with Netlify first, as this can be changed later. The way to write Toml files is described in Configure Hugo. Push to Github Create a repository on Github.\nAfter creation, execute the following commands to push your site.\n1 2 3 4 5 6 7 8 9 10 cd my-blog echo .hugo_build.lock \u0026gt;\u0026gt; .gitignore git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main # Replace \u0026lt;user name\u0026gt; with your own username. # This is an example of creating a repository called my-blog. git remote add origin git@github.com:\u0026lt;user name\u0026gt;/my-blog git push -u origin main Once the push is complete, the source code becomes viewable on the Github UI.\nDeploy with Netlify Access Netlify and perform deployment.\nThere are instructions on Hugo\u0026rsquo;s official website, so refer to them for integration.\nFollow the instructions to complete the deployment, and the result of the Deploy will be shown as published.\nClick on the URL displayed on the site to access the deployed site. This completes the deployment process. After this, any changes made and pushed to main will automatically trigger deployment, updating the site content.\n","date":"2023-12-02T00:59:37+09:00","permalink":"https://bossagyu.com/en/blog/001-hugo-netlify-build/","title":"Publishing a Blog with Hugo + Netlify + Github"}]